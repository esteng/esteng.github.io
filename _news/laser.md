---
layout: post
date: 2024-10-02 21:00:00-0400
inline: true
---

New preprint! [LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits](https://arxiv.org/abs/2410.01735) led by [Duy Nguyen](https://duykhuongnguyen.github.io) and [Archiki Prasad](https://archiki.github.io) with [Mohit Bansal](https://www.cs.unc.edu/~mbansal/) on using bandit methods to pick the best-suited RM to optimize at an instance level, improving LLMs on reasoning, instruction-following, and long-context understanding. 

