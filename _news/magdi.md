---
layout: post
date: 2024-02-02 21:00:00-0400
inline: true
---

New work led by [Justin Chen](https://dinobby.github.io) and [Swarnadeep Saha](https://swarnahub.github.io) on distilling multi-agent LLM interactions into smaller models: [MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models
](https://arxiv.org/abs/2402.01620). MAGDi uses a graph structure on top of LLM dialogues to distill reasoning from several large teacher models into a single, lightweight student. 
